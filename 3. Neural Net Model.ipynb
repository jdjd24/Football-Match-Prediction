{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.preprocessing as preprocessing\n",
    "import sklearn.metrics\n",
    "import math\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch import Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.read_csv('x_train_full.csv')\n",
    "x_val = pd.read_csv('x_val_full.csv')\n",
    "x_test = pd.read_csv('x_test_full.csv')\n",
    "y_train = pd.read_csv('./Data with correct player_atts/y_train.csv')\n",
    "y_val = pd.read_csv('./Data with correct player_atts/y_val.csv')\n",
    "y_test = pd.read_csv('./Data with correct player_atts/y_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {1:0, 0:1, -1:2 }\n",
    "y_train['target'] = y_train['result'].map(label_dict)\n",
    "y_val['target'] =  y_val['result'].map(label_dict)\n",
    "y_test['target'] =  y_test['result'].map(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16673"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train.match_api_id == y_train.match_api_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Rebalance proportion of home wins/draws/home losses\n",
    "incides = y_train[y_train['result'] == 1].sample(frac = 0.35).index.values\n",
    "mask_y= ~ y_train.index.isin(indices)\n",
    "mask_x= ~ x_train.index.isin(indices)\n",
    "y_train = y_train[mask_y]\n",
    "x_train = x_train[mask_x]\n",
    "assert len(x_train) == len(y_train)\n",
    "assert (x_train.index == y_train.index).sum()\n",
    "assert (x_train.match_api_id == y_train.match_api_id).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "x_train = pd.DataFrame(min_max_scaler.fit_transform(x_train.iloc[:,1:]), index = x_train['match_api_id'], columns = x_train.iloc[:,1:].columns)\n",
    "x_val = pd.DataFrame(min_max_scaler.fit_transform(x_val.iloc[:,1:]), index = x_val['match_api_id'], columns = x_val.iloc[:,1:].columns)\n",
    "x_test = pd.DataFrame(min_max_scaler.fit_transform(x_test.iloc[:,1:]), index = x_test['match_api_id'], columns = x_test.iloc[:,1:].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    0.458586\n",
       "-1    0.289090\n",
       " 0    0.252324\n",
       "Name: result, dtype: float64"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train['result'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Network\n",
    "input_size = len(x_train.columns)\n",
    "hidden_sizes = [512,256,256,256,64,32]\n",
    "output_size = 3\n",
    "\n",
    "# Build a feed-forward network\n",
    "LinearNN = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.Tanh(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], hidden_sizes[2]),\n",
    "                        nn.ReLU(),\n",
    "                        nn.Linear(hidden_sizes[2], hidden_sizes[3]),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(hidden_sizes[3], hidden_sizes[4]),\n",
    "                        nn.ReLU(),\n",
    "                         nn.Linear(hidden_sizes[4], hidden_sizes[5]),\n",
    "                        nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[5], output_size),\n",
    "                      nn.Softmax()\n",
    "                        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "batch_size = 512 #len(x_train)\n",
    "epochs = 10\n",
    "learning_rate = 0.001\n",
    "loss = 0\n",
    "losses = []\n",
    "counter = 0\n",
    "\n",
    "dataset = TensorDataset( Tensor(x_train.values), torch.Tensor(y_train['target'].values) )\n",
    "train_loader = DataLoader(dataset, batch_size = batch_size, shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.Adam(LinearNN.parameters(), lr=learning_rate, betas=(0.8,0.999))\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size= 5 , gamma = 0.1)\n",
    "mse = torch.nn.MSELoss()\n",
    "cross = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss after iteration 0: 1.1061350107192993\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "\n",
    "t = time.time()\n",
    "for epoch in range(epochs):\n",
    "    for x, y in iter(train_loader):\n",
    "        LinearNN.train()\n",
    "        LinearNN.zero_grad()\n",
    "        \n",
    "        y_pred = LinearNN(x)\n",
    "        loss = cross(y_pred, y.long())\n",
    "        \n",
    "        if counter % 500 ==0:\n",
    "            print('Loss after iteration {}: {}'.format(counter, loss.item()))\n",
    "        \n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        counter+=1 \n",
    "    counter+=1\n",
    "    scheduler.step()\n",
    "time.time()-t        \n",
    "        \n",
    "        \n",
    "print('Elapsed time: {} s'.format(time.time()-t))    \n",
    "print(loss.item())  \n",
    "plt.plot(range(len(losses)), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Eval \n",
    "\n",
    "LinearNN.eval()\n",
    "with torch.no_grad():\n",
    "    val_pred = LinearNN(Tensor(x_val.values))\n",
    "    \n",
    "y_val_pred = pd.Series(val_pred.max(1).indices).map({0:1,1:0,2:-1})\n",
    "sklearn.metrics.accuracy_score(y_val_pred, y_val['result'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6496, 0.1033, 0.2471],\n",
       "        [0.6608, 0.0983, 0.2408],\n",
       "        [0.6526, 0.1020, 0.2454],\n",
       "        [0.6572, 0.0999, 0.2428],\n",
       "        [0.6951, 0.0838, 0.2212],\n",
       "        [0.6632, 0.0973, 0.2395],\n",
       "        [0.6541, 0.1013, 0.2446],\n",
       "        [0.6778, 0.0910, 0.2312],\n",
       "        [0.6797, 0.0902, 0.2301],\n",
       "        [0.6567, 0.1002, 0.2431],\n",
       "        [0.6647, 0.0966, 0.2386],\n",
       "        [0.6747, 0.0923, 0.2330],\n",
       "        [0.6627, 0.0976, 0.2398],\n",
       "        [0.6915, 0.0853, 0.2233],\n",
       "        [0.6693, 0.0946, 0.2360],\n",
       "        [0.6497, 0.1033, 0.2470],\n",
       "        [0.6649, 0.0966, 0.2385],\n",
       "        [0.6857, 0.0877, 0.2266],\n",
       "        [0.6599, 0.0987, 0.2413],\n",
       "        [0.6943, 0.0841, 0.2216],\n",
       "        [0.6542, 0.1013, 0.2445],\n",
       "        [0.6806, 0.0898, 0.2296],\n",
       "        [0.6762, 0.0917, 0.2321],\n",
       "        [0.6711, 0.0939, 0.2350],\n",
       "        [0.6647, 0.0967, 0.2387],\n",
       "        [0.6733, 0.0929, 0.2338],\n",
       "        [0.6740, 0.0926, 0.2334],\n",
       "        [0.6710, 0.0939, 0.2351],\n",
       "        [0.6925, 0.0848, 0.2227],\n",
       "        [0.6776, 0.0911, 0.2313],\n",
       "        [0.6703, 0.0942, 0.2355],\n",
       "        [0.6864, 0.0874, 0.2262],\n",
       "        [0.6679, 0.0953, 0.2368],\n",
       "        [0.6665, 0.0959, 0.2376],\n",
       "        [0.6557, 0.1006, 0.2437],\n",
       "        [0.6692, 0.0947, 0.2361],\n",
       "        [0.6614, 0.0981, 0.2405],\n",
       "        [0.6723, 0.0934, 0.2343],\n",
       "        [0.6590, 0.0991, 0.2418],\n",
       "        [0.6696, 0.0945, 0.2359],\n",
       "        [0.6667, 0.0958, 0.2375],\n",
       "        [0.6695, 0.0946, 0.2359],\n",
       "        [0.6655, 0.0963, 0.2382],\n",
       "        [0.6659, 0.0961, 0.2380],\n",
       "        [0.6646, 0.0967, 0.2387],\n",
       "        [0.6779, 0.0910, 0.2312],\n",
       "        [0.6861, 0.0875, 0.2264],\n",
       "        [0.6777, 0.0910, 0.2312],\n",
       "        [0.6815, 0.0894, 0.2291],\n",
       "        [0.6701, 0.0943, 0.2356],\n",
       "        [0.6676, 0.0954, 0.2370],\n",
       "        [0.6659, 0.0961, 0.2380],\n",
       "        [0.6779, 0.0910, 0.2311],\n",
       "        [0.6768, 0.0915, 0.2318],\n",
       "        [0.6919, 0.0851, 0.2230],\n",
       "        [0.6701, 0.0943, 0.2356],\n",
       "        [0.6695, 0.0946, 0.2359],\n",
       "        [0.6676, 0.0954, 0.2370],\n",
       "        [0.6774, 0.0912, 0.2314],\n",
       "        [0.6821, 0.0892, 0.2287],\n",
       "        [0.6579, 0.0997, 0.2425],\n",
       "        [0.6743, 0.0925, 0.2332],\n",
       "        [0.6817, 0.0894, 0.2289],\n",
       "        [0.6678, 0.0953, 0.2369],\n",
       "        [0.6584, 0.0994, 0.2422],\n",
       "        [0.6675, 0.0954, 0.2370],\n",
       "        [0.6541, 0.1013, 0.2446],\n",
       "        [0.6488, 0.1037, 0.2475],\n",
       "        [0.6512, 0.1026, 0.2462],\n",
       "        [0.6563, 0.1003, 0.2433],\n",
       "        [0.6640, 0.0970, 0.2390],\n",
       "        [0.6756, 0.0920, 0.2325],\n",
       "        [0.6614, 0.0981, 0.2405],\n",
       "        [0.6907, 0.0856, 0.2237],\n",
       "        [0.6735, 0.0929, 0.2337],\n",
       "        [0.6819, 0.0893, 0.2288],\n",
       "        [0.6734, 0.0929, 0.2337],\n",
       "        [0.6754, 0.0921, 0.2326],\n",
       "        [0.6608, 0.0983, 0.2408],\n",
       "        [0.6658, 0.0962, 0.2380],\n",
       "        [0.6870, 0.0871, 0.2258],\n",
       "        [0.6684, 0.0950, 0.2365],\n",
       "        [0.6730, 0.0931, 0.2340],\n",
       "        [0.6678, 0.0953, 0.2369],\n",
       "        [0.6802, 0.0900, 0.2298],\n",
       "        [0.6898, 0.0859, 0.2242],\n",
       "        [0.6746, 0.0924, 0.2330],\n",
       "        [0.6770, 0.0913, 0.2316],\n",
       "        [0.6928, 0.0847, 0.2225],\n",
       "        [0.6588, 0.0992, 0.2420],\n",
       "        [0.6641, 0.0969, 0.2390],\n",
       "        [0.6524, 0.1021, 0.2455],\n",
       "        [0.6637, 0.0971, 0.2392],\n",
       "        [0.6546, 0.1011, 0.2443],\n",
       "        [0.6536, 0.1015, 0.2448],\n",
       "        [0.6659, 0.0961, 0.2380],\n",
       "        [0.6545, 0.1011, 0.2444],\n",
       "        [0.6705, 0.0941, 0.2354],\n",
       "        [0.6669, 0.0957, 0.2374],\n",
       "        [0.6657, 0.0962, 0.2381],\n",
       "        [0.6633, 0.0972, 0.2394],\n",
       "        [0.6685, 0.0950, 0.2365],\n",
       "        [0.6615, 0.0981, 0.2405],\n",
       "        [0.6620, 0.0979, 0.2402],\n",
       "        [0.6905, 0.0857, 0.2238],\n",
       "        [0.6879, 0.0867, 0.2254],\n",
       "        [0.6624, 0.0976, 0.2399],\n",
       "        [0.6694, 0.0946, 0.2360],\n",
       "        [0.6712, 0.0938, 0.2350],\n",
       "        [0.6665, 0.0959, 0.2376],\n",
       "        [0.6520, 0.1022, 0.2457],\n",
       "        [0.6721, 0.0935, 0.2345],\n",
       "        [0.6552, 0.1008, 0.2440],\n",
       "        [0.6902, 0.0858, 0.2240],\n",
       "        [0.6804, 0.0899, 0.2297],\n",
       "        [0.6637, 0.0971, 0.2392],\n",
       "        [0.6897, 0.0860, 0.2243],\n",
       "        [0.6838, 0.0884, 0.2277],\n",
       "        [0.6724, 0.0934, 0.2343],\n",
       "        [0.6863, 0.0874, 0.2263],\n",
       "        [0.6659, 0.0961, 0.2379],\n",
       "        [0.6668, 0.0957, 0.2375],\n",
       "        [0.6574, 0.0999, 0.2428],\n",
       "        [0.6676, 0.0954, 0.2370],\n",
       "        [0.6807, 0.0898, 0.2295],\n",
       "        [0.6630, 0.0974, 0.2396],\n",
       "        [0.6729, 0.0931, 0.2340],\n",
       "        [0.6527, 0.1020, 0.2454],\n",
       "        [0.6603, 0.0986, 0.2411],\n",
       "        [0.6711, 0.0939, 0.2350],\n",
       "        [0.6706, 0.0941, 0.2353],\n",
       "        [0.6546, 0.1011, 0.2443],\n",
       "        [0.6590, 0.0991, 0.2418],\n",
       "        [0.6592, 0.0991, 0.2417],\n",
       "        [0.6499, 0.1032, 0.2469],\n",
       "        [0.6591, 0.0991, 0.2418],\n",
       "        [0.6535, 0.1016, 0.2449],\n",
       "        [0.6829, 0.0889, 0.2283],\n",
       "        [0.6675, 0.0955, 0.2371],\n",
       "        [0.6734, 0.0929, 0.2337],\n",
       "        [0.6610, 0.0983, 0.2407],\n",
       "        [0.6665, 0.0959, 0.2376],\n",
       "        [0.6667, 0.0958, 0.2375],\n",
       "        [0.6831, 0.0887, 0.2281],\n",
       "        [0.6762, 0.0917, 0.2321],\n",
       "        [0.6697, 0.0945, 0.2358],\n",
       "        [0.6803, 0.0900, 0.2298],\n",
       "        [0.6867, 0.0873, 0.2261],\n",
       "        [0.6590, 0.0992, 0.2419],\n",
       "        [0.6603, 0.0986, 0.2411],\n",
       "        [0.6604, 0.0985, 0.2411],\n",
       "        [0.6693, 0.0947, 0.2361],\n",
       "        [0.6730, 0.0930, 0.2339],\n",
       "        [0.6688, 0.0949, 0.2363],\n",
       "        [0.6594, 0.0990, 0.2416],\n",
       "        [0.6673, 0.0955, 0.2371],\n",
       "        [0.6677, 0.0954, 0.2370],\n",
       "        [0.6668, 0.0957, 0.2374],\n",
       "        [0.6514, 0.1025, 0.2460],\n",
       "        [0.6673, 0.0955, 0.2372],\n",
       "        [0.6657, 0.0962, 0.2381],\n",
       "        [0.6528, 0.1019, 0.2453],\n",
       "        [0.6758, 0.0919, 0.2323],\n",
       "        [0.6681, 0.0952, 0.2367],\n",
       "        [0.6733, 0.0930, 0.2338],\n",
       "        [0.6710, 0.0939, 0.2351],\n",
       "        [0.6694, 0.0946, 0.2360],\n",
       "        [0.6662, 0.0960, 0.2378],\n",
       "        [0.6595, 0.0989, 0.2416],\n",
       "        [0.6879, 0.0867, 0.2254],\n",
       "        [0.6767, 0.0915, 0.2318],\n",
       "        [0.6660, 0.0961, 0.2379],\n",
       "        [0.6904, 0.0857, 0.2239],\n",
       "        [0.6761, 0.0917, 0.2321],\n",
       "        [0.6666, 0.0958, 0.2376],\n",
       "        [0.6597, 0.0988, 0.2414],\n",
       "        [0.6711, 0.0939, 0.2350],\n",
       "        [0.6564, 0.1003, 0.2433],\n",
       "        [0.6820, 0.0892, 0.2288],\n",
       "        [0.6738, 0.0927, 0.2335],\n",
       "        [0.6755, 0.0920, 0.2325],\n",
       "        [0.6677, 0.0954, 0.2370],\n",
       "        [0.6694, 0.0946, 0.2360],\n",
       "        [0.6549, 0.1009, 0.2441],\n",
       "        [0.6688, 0.0949, 0.2363],\n",
       "        [0.6611, 0.0982, 0.2407],\n",
       "        [0.6542, 0.1013, 0.2445],\n",
       "        [0.6653, 0.0964, 0.2383],\n",
       "        [0.6547, 0.1010, 0.2442],\n",
       "        [0.6729, 0.0931, 0.2340],\n",
       "        [0.6822, 0.0891, 0.2286],\n",
       "        [0.6954, 0.0836, 0.2210],\n",
       "        [0.6795, 0.0903, 0.2302],\n",
       "        [0.6838, 0.0885, 0.2277],\n",
       "        [0.6809, 0.0897, 0.2294],\n",
       "        [0.6845, 0.0882, 0.2273],\n",
       "        [0.6762, 0.0917, 0.2321],\n",
       "        [0.6580, 0.0996, 0.2424],\n",
       "        [0.6916, 0.0852, 0.2232],\n",
       "        [0.6765, 0.0915, 0.2319],\n",
       "        [0.6670, 0.0957, 0.2374],\n",
       "        [0.6850, 0.0879, 0.2270],\n",
       "        [0.6656, 0.0963, 0.2381],\n",
       "        [0.6603, 0.0986, 0.2411],\n",
       "        [0.6547, 0.1010, 0.2442],\n",
       "        [0.6546, 0.1011, 0.2443],\n",
       "        [0.6544, 0.1012, 0.2444],\n",
       "        [0.6573, 0.0999, 0.2428],\n",
       "        [0.6772, 0.0913, 0.2315],\n",
       "        [0.6692, 0.0947, 0.2361],\n",
       "        [0.6535, 0.1016, 0.2449],\n",
       "        [0.6727, 0.0932, 0.2341],\n",
       "        [0.6579, 0.0996, 0.2425],\n",
       "        [0.6683, 0.0951, 0.2366],\n",
       "        [0.6502, 0.1031, 0.2467],\n",
       "        [0.6636, 0.0971, 0.2392],\n",
       "        [0.6784, 0.0907, 0.2308],\n",
       "        [0.6605, 0.0985, 0.2410],\n",
       "        [0.6673, 0.0955, 0.2372],\n",
       "        [0.6619, 0.0979, 0.2402],\n",
       "        [0.6578, 0.0997, 0.2425],\n",
       "        [0.6782, 0.0908, 0.2309],\n",
       "        [0.6847, 0.0881, 0.2272],\n",
       "        [0.6530, 0.1018, 0.2452],\n",
       "        [0.6691, 0.0948, 0.2362],\n",
       "        [0.6715, 0.0937, 0.2348],\n",
       "        [0.6611, 0.0983, 0.2407],\n",
       "        [0.6768, 0.0914, 0.2317],\n",
       "        [0.6542, 0.1013, 0.2446],\n",
       "        [0.6779, 0.0910, 0.2311],\n",
       "        [0.6662, 0.0960, 0.2378],\n",
       "        [0.6513, 0.1025, 0.2461],\n",
       "        [0.6854, 0.0878, 0.2268],\n",
       "        [0.6726, 0.0932, 0.2342],\n",
       "        [0.6538, 0.1014, 0.2447],\n",
       "        [0.6600, 0.0987, 0.2413],\n",
       "        [0.6612, 0.0982, 0.2406],\n",
       "        [0.6632, 0.0973, 0.2395],\n",
       "        [0.6647, 0.0967, 0.2386],\n",
       "        [0.6827, 0.0889, 0.2284],\n",
       "        [0.6903, 0.0857, 0.2239],\n",
       "        [0.6633, 0.0973, 0.2394],\n",
       "        [0.6647, 0.0967, 0.2386],\n",
       "        [0.6687, 0.0949, 0.2364],\n",
       "        [0.6589, 0.0992, 0.2419],\n",
       "        [0.6636, 0.0972, 0.2393],\n",
       "        [0.6702, 0.0943, 0.2355],\n",
       "        [0.6587, 0.0993, 0.2420],\n",
       "        [0.6818, 0.0893, 0.2289],\n",
       "        [0.6647, 0.0967, 0.2387],\n",
       "        [0.6780, 0.0909, 0.2310],\n",
       "        [0.6670, 0.0957, 0.2374],\n",
       "        [0.6794, 0.0903, 0.2302],\n",
       "        [0.6776, 0.0911, 0.2313],\n",
       "        [0.6686, 0.0950, 0.2364],\n",
       "        [0.6681, 0.0952, 0.2367],\n",
       "        [0.6520, 0.1022, 0.2457],\n",
       "        [0.6782, 0.0908, 0.2309],\n",
       "        [0.6758, 0.0919, 0.2323],\n",
       "        [0.6594, 0.0990, 0.2416],\n",
       "        [0.6767, 0.0915, 0.2318],\n",
       "        [0.6676, 0.0954, 0.2370],\n",
       "        [0.6701, 0.0943, 0.2356],\n",
       "        [0.6665, 0.0959, 0.2376],\n",
       "        [0.6690, 0.0948, 0.2362],\n",
       "        [0.6702, 0.0943, 0.2356],\n",
       "        [0.6763, 0.0916, 0.2321],\n",
       "        [0.6896, 0.0860, 0.2243],\n",
       "        [0.6734, 0.0929, 0.2337],\n",
       "        [0.6769, 0.0914, 0.2317],\n",
       "        [0.6563, 0.1004, 0.2434],\n",
       "        [0.6650, 0.0965, 0.2385],\n",
       "        [0.6711, 0.0939, 0.2350],\n",
       "        [0.6578, 0.0997, 0.2425],\n",
       "        [0.6632, 0.0973, 0.2395],\n",
       "        [0.6723, 0.0934, 0.2343],\n",
       "        [0.6653, 0.0964, 0.2383],\n",
       "        [0.6913, 0.0853, 0.2234],\n",
       "        [0.6544, 0.1012, 0.2444],\n",
       "        [0.6709, 0.0940, 0.2351],\n",
       "        [0.6743, 0.0925, 0.2332],\n",
       "        [0.6751, 0.0922, 0.2327],\n",
       "        [0.6712, 0.0938, 0.2350],\n",
       "        [0.6688, 0.0949, 0.2363],\n",
       "        [0.6874, 0.0869, 0.2256],\n",
       "        [0.6687, 0.0949, 0.2364],\n",
       "        [0.6722, 0.0934, 0.2344],\n",
       "        [0.6643, 0.0968, 0.2389],\n",
       "        [0.6691, 0.0948, 0.2362]], grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
